{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wikipedia Implementing Glove",
      "provenance": [],
      "mount_file_id": "18HK_0HesWACZv9or0hldodpmPLQ4cgwL",
      "authorship_tag": "ABX9TyPjBMOA9iGbgEURpdJAX6Mi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tushitgarg/Hate-Speech-Content-Moderation/blob/master/Wikipedia_Implementing_Glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKzM9FwITlm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "3efd053e-8c5a-4861-a6c0-a5f7f8079c4e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pprint as pp\n",
        "! pip install normalise\n",
        "import nltk\n",
        "nltk.download('names')\n",
        "nltk.download('brown')\n",
        "\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "import string\n",
        "import spacy \n",
        "import en_core_web_sm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from normalise import normalise\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,GRU, SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import layers\n",
        "from keras.initializers import Constant\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: normalise in /usr/local/lib/python3.6/dist-packages (0.1.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from normalise) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from normalise) (0.22.2.post1)\n",
            "Requirement already satisfied: roman in /usr/local/lib/python3.6/dist-packages (from normalise) (3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from normalise) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from normalise) (1.18.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->normalise) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->normalise) (1.12.0)\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEZk9xvrJbxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b34ad0e6-a107-4f48-e2ae-4db71b763029"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0AYkCr6Tvdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1869a7f-daff-4d17-e35d-8ebccc7283da"
      },
      "source": [
        "cd '/content/drive/My Drive/minor2/Hate-Speech-Content-Moderation/'"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/minor2/Hate-Speech-Content-Moderation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqE2ANuCTwxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install -q kaggle\n",
        "#from google.colab import files\n",
        "#files.upload()\n",
        "#! mkdir ~/.kaggle \n",
        "#! cp kaggle.json ~/.kaggle/\n",
        "#! chmod 600 ~/.kaggle/kaggle.json\n",
        "#! kaggle datasets list\n",
        "#! kaggle competitions download -c 'quora-insincere-questions-classification'\n",
        "#! unzip train.csv.zip -d train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XEAvKu7Wt1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3d7842b9-9d0f-495a-e7e0-f0832e074849"
      },
      "source": [
        "df1=pd.read_excel('wiki.xlsx')\n",
        "#df1.drop(['level_0','index','Unnamed: 0'],axis=1,inplace=True)\n",
        "df1.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4873f24af8928f39</td>\n",
              "      <td>Oh BedWetter... please stop your furious back-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aa343515b55c73b8</td>\n",
              "      <td>There's no conflict, a court martial can end w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c7888738107f928a</td>\n",
              "      <td>what????how are the ones from willking1979's t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48a42a867206a816</td>\n",
              "      <td>\"\\n\\nabuse or consentual??\\n\\n\"\"Homolka would ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2c103909d79f9876</td>\n",
              "      <td>\"==Talk:\"\"Lane Splitting\"\"==\\n\\nDennis, why do...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                               text  label\n",
              "0  4873f24af8928f39  Oh BedWetter... please stop your furious back-...      1\n",
              "1  aa343515b55c73b8  There's no conflict, a court martial can end w...      0\n",
              "2  c7888738107f928a  what????how are the ones from willking1979's t...      0\n",
              "3  48a42a867206a816  \"\\n\\nabuse or consentual??\\n\\n\"\"Homolka would ...      0\n",
              "4  2c103909d79f9876  \"==Talk:\"\"Lane Splitting\"\"==\\n\\nDennis, why do...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pa5VOqSdX8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1['label'] = df1['label'].fillna('').apply(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7OqBXJkaTRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "38ea0472-e550-407e-f3c2-15e1d58db64a"
      },
      "source": [
        "df1[df1['text']==0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [id, text, label]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPXszGbhXEa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62e0bb84-2327-4634-d82b-7a15d5d2b516"
      },
      "source": [
        "np.mean(df1['label'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDIR-mrFXFf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=df1['text']\n",
        "labels=df1['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1sxHhVTXKl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,\n",
        "                 variety=\"BrE\",\n",
        "                 user_abbrevs={},\n",
        "                 n_jobs=1):\n",
        "        \"\"\"\n",
        "        Text preprocessing transformer includes steps:\n",
        "            1. Text normalization\n",
        "            2. Punctuation removal\n",
        "            3. Stop words removal\n",
        "            4. Lemmatization\n",
        "        \n",
        "        variety - format of date (AmE - american type, BrE - british format) \n",
        "        user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
        "        n_jobs - parallel jobs to run\n",
        "        \"\"\"\n",
        "        self.variety = variety\n",
        "        self.user_abbrevs = user_abbrevs\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, *_):\n",
        "        X_copy = X.copy()\n",
        "        return X_copy.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_part(self, part):\n",
        "        return part.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_text(self, text):\n",
        "        text=self._clean_text(text)\n",
        "        normalized_text = self._normalize(text)\n",
        "        doc = nlp(normalized_text)\n",
        "        removed_punct = self._remove_punct(doc)\n",
        "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
        "        return self._lemmatize(removed_stop_words)\n",
        "\n",
        "    def _normalize(self, text):\n",
        "        # some issues in normalise package\n",
        "        try:\n",
        "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
        "        except:\n",
        "            return text\n",
        "\n",
        "    def _remove_punct(self, doc):\n",
        "        return [t for t in doc if t.text not in string.punctuation]\n",
        "\n",
        "    def _remove_stop_words(self, doc):\n",
        "        return [t for t in doc if not t.is_stop]\n",
        "\n",
        "    def _lemmatize(self, doc):\n",
        "        return ' '.join([t.lemma_ for t in doc])\n",
        "    \n",
        "    \n",
        "    def _clean_text(self,text):\n",
        "      replace_1 = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
        "      replace_2 = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "      try:\n",
        "        text=re.sub(r\"http\\S+\", \"\", text)\n",
        "      except:\n",
        "        print(text)\n",
        "      text = replace_1.sub(\"\", text)\n",
        "      text = replace_2.sub(\" \", text)\n",
        "      text=re.sub('\\s+',' ',text)\n",
        "      return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU4hYniXXLqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aa0f852e-862c-4e8a-e125-7b346f9cfb81"
      },
      "source": [
        "%%time\n",
        "text = TextPreprocessor(n_jobs=-1).transform(df1['text'])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 50s, sys: 1.08 s, total: 2min 51s\n",
            "Wall time: 2min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWABQ6WJZpRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2=[]\n",
        "for i in text:\n",
        "      lst=i.split()\n",
        "      text2.append(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPFMfqgclszO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYWRdXo-Ke_N",
        "colab_type": "code",
        "outputId": "45172f1c-717e-4ce0-edf3-2332d590e049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "exdf=pd.DataFrame()\n",
        "exdf['text']=[\"hello my \\n is ./.,is tushit's \\t @344$%% what are you D.R   running  doing?? please HELP!!\"]\n",
        "clean_ex = TextPreprocessor(n_jobs=-1).transform(exdf['text'])\n",
        "print(clean_ex[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello tushit @344$%% DR run help\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezgv6XbVZzVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1c1683c1-1369-43b2-b438-27380d17268e"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(text2) \n",
        "sequences = tokenizer.texts_to_sequences(text2)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.',len(word_index))\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = max([len(s.split()) for s in text])\n",
        "tweets_pad = pad_sequences(sequences, maxlen=maxlen)\n",
        "print(tweets_pad.shape) \n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found %s unique tokens. 32848\n",
            "(10204, 1250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozO9OcYoledW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3=pd.concat([pd.DataFrame(text),pd.DataFrame(tweets_pad)],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efA0KrFtl7Zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6e616a7b-0af5-47c2-b8e5-64127a1bc620"
      },
      "source": [
        "print('Loading word vectors')\n",
        "embeddings_index = {} # We create a dictionary of word -> embedding\n",
        "f = open('/content/drive/My Drive/minor2/twitter2/glove.6B.100d.txt','r') # Open file\n",
        "# In the dataset, each line represents a new word embedding\n",
        "# The line starts with the word and the embedding values follow\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    word = values[0] # The first value is the word, the rest are the values of the embedding\n",
        "    values = np.asarray(values[1:], dtype='float32') # Load embedding\n",
        "    embeddings_index[word] = values # Add embedding to our embedding dictionary\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "400001it [00:14, 27319.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 400001 word vectors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8D78S-cmawT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "37a55a47-f317-4ad7-b48b-41716ab93dcf"
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean = all_embs.mean() # Calculate mean\n",
        "emb_std = all_embs.std() # Calculate standard deviation\n",
        "emb_mean,emb_std"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0044520576, 0.40815717)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU9UGIrumfPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = len(word_index)+1\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z05JnXjmmg9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "419ac849-6677-4db5-a99e-1912198e9bfc"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32849, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZbNZxY4mjVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history,name_of_fig):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    f=plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    f.savefig(name_of_fig, bbox_inches='tight', dpi=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGsunE-fmmS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            weights = [embedding_matrix],\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "#model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijV_-HN8mpSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "2fd3ccde-950c-43fa-8d44-161066ec6d82"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dropout(.3))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1250, 100)         3284900   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 3,365,401\n",
            "Trainable params: 80,501\n",
            "Non-trainable params: 3,284,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hif35F0tmrzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(GRU(units=100,dropout=0.2 , recurrent_dropout=0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIMBsJkJmvPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dense(10, activation='sigmoid'))\n",
        "#model.add(GRU(units=100,dropout=0.2 , recurrent_dropout=0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1YYCufmzn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "#model.add(Flatten())\n",
        "model.add(SimpleRNN(32, dropout=.2, recurrent_dropout=.2))\n",
        "model.add(layers.Dense(10, activation='sigmoid'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBvPFV5Cm1bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_testing ,y_train, y_testing = train_test_split(df3, labels, test_size = 0.60, random_state = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNYsK3dKm3XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test, X_val ,y_test, y_val = train_test_split(X_testing, y_testing, test_size = 0.50, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynACvjJZm5XM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "fbb151a1-5aa1-4a4b-c419-9913bf9314d8"
      },
      "source": [
        "print('Training.....')\n",
        "history=model.fit(X_train.iloc[:,1:], y_train, batch_size=256,epochs=5,validation_data=(X_val.iloc[:,1:],y_val),verbose=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "Train on 4081 samples, validate on 3062 samples\n",
            "Epoch 1/5\n",
            "4081/4081 [==============================] - 125s 31ms/step - loss: 0.3969 - accuracy: 0.8270 - val_loss: 0.3378 - val_accuracy: 0.8628\n",
            "Epoch 2/5\n",
            "4081/4081 [==============================] - 125s 31ms/step - loss: 0.3426 - accuracy: 0.8527 - val_loss: 0.3169 - val_accuracy: 0.8668\n",
            "Epoch 3/5\n",
            "4081/4081 [==============================] - 124s 31ms/step - loss: 0.3203 - accuracy: 0.8633 - val_loss: 0.2981 - val_accuracy: 0.8756\n",
            "Epoch 4/5\n",
            "4081/4081 [==============================] - 124s 30ms/step - loss: 0.3139 - accuracy: 0.8662 - val_loss: 0.3126 - val_accuracy: 0.8703\n",
            "Epoch 5/5\n",
            "4081/4081 [==============================] - 126s 31ms/step - loss: 0.2893 - accuracy: 0.8790 - val_loss: 0.2817 - val_accuracy: 0.8795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xueIfUK9m70m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_classes=model.predict_classes(X_test.iloc[:,1:])\n",
        "y_test = y_test.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAH9tYsxm9Wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "66a3a830-7814-44f4-a209-276e34eee988"
      },
      "source": [
        "print(len(X_val))\n",
        "print(len(y_val))\n",
        "print(df3.shape)\n",
        "print(len(labels))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3062\n",
            "3062\n",
            "(10204, 1251)\n",
            "10204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW1OP26cm_N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.DataFrame({'y_test': y_test, 'y_classes': y_classes[:,0]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTs0gx_-nGpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f59bf2e3-cd41-47ab-b264-39736190f5d7"
      },
      "source": [
        "1-np.mean(dataset['y_test'])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7164325383861483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G5QLEJVnJrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0oDrDBPnLPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "8067cb8a-f7a3-43b8-c442-a0d01d6b9e93"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, y_classes)\n",
        "print('Accuracy:{}\\n'.format(accuracy))\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_classes)\n",
        "print('Precision:{}\\n'.format(precision))\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, y_classes)\n",
        "print('Recall:{}\\n'.format(recall))\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_classes)\n",
        "print('F1 score:{}\\n'.format(f1))\n",
        "matrix = confusion_matrix(y_test, y_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.8801045409996733\n",
            "\n",
            "Precision:0.8119551681195517\n",
            "\n",
            "Recall:0.7511520737327189\n",
            "\n",
            "F1 score:0.7803710353081986\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2042  151]\n",
            " [ 216  652]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}