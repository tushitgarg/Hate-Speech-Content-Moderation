{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora_Glove.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tushitgarg/Hate-Speech-Content-Moderation/blob/master/Quora_Glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xOs5XYeSwPS",
        "colab_type": "code",
        "outputId": "0a09ffad-8c4f-456b-eb0e-9a2b5997bb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pprint as pp\n",
        "! pip install normalise\n",
        "import nltk\n",
        "nltk.download('names')\n",
        "nltk.download('brown')\n",
        "\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "import string\n",
        "import spacy \n",
        "import en_core_web_sm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from normalise import normalise\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,GRU, SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import layers\n",
        "from keras.initializers import Constant\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting normalise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/2d/f06cf3d3714502dec10e19238a5da201b71ce198165beda9c1adaf5063da/normalise-0.1.8-py3-none-any.whl (15.7MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7MB 250kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from normalise) (3.2.5)\n",
            "Collecting roman\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/f2/29d1d069555855ed49c74b627e6af73cec7a5f4de27c200ea0d760939da4/roman-3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from normalise) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from normalise) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from normalise) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->normalise) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->normalise) (0.15.1)\n",
            "Installing collected packages: roman, normalise\n",
            "Successfully installed normalise-0.1.8 roman-3.2\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.semi_supervised.label_propagation module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.semi_supervised. Anything that cannot be imported from sklearn.semi_supervised is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelPropagation from version 0.18 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGN82vGyS5q4",
        "colab_type": "code",
        "outputId": "681ccbe5-3d82-4999-dc4e-675381778a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRUWwmEIS7ZE",
        "colab_type": "code",
        "outputId": "d3b71340-5131-451c-824e-28b1b3c1d04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd '/content/drive/My Drive/minor2/Hate-Speech-Content-Moderation/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/minor2/Hate-Speech-Content-Moderation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA696pJjTCx6",
        "colab_type": "code",
        "outputId": "999ef3ee-9a99-4f94-dec6-6f594e3dd1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df1=pd.read_excel('quora.xlsx')\n",
        "#df1.drop(['level_0','index','Unnamed: 0'],axis=1,inplace=True)\n",
        "df1.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8eeb2fa6a60d93c5ce3c</td>\n",
              "      <td>What is the difference between real, true, act...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>420689e2da77a9254362</td>\n",
              "      <td>Can an applicant with JEST score in PhD merit ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b4d8ce47a727326a8916</td>\n",
              "      <td>How can I get the syllabus of JEE Advanced for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>197be9aa5fbef88659ee</td>\n",
              "      <td>What is fee structure of KLE Sheshagiri Colleg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a05cc194d3952fce5856</td>\n",
              "      <td>How do I pick few wines that will go with food...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>e1ddc63412371760c4f8</td>\n",
              "      <td>Where can I find a list of products that use S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4ceb54eb7d9d41e447b8</td>\n",
              "      <td>Did you ever watch your wife have sex?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>911a6777272ef36f45f4</td>\n",
              "      <td>What are door and window hardware commonly use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3038fbfa8d74e8e57c9d</td>\n",
              "      <td>Why do we cancel a product purchased online?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>b2ae47cfd86ae994440a</td>\n",
              "      <td>Do people who speak no languages think in pict...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... label\n",
              "0  8eeb2fa6a60d93c5ce3c  ...     0\n",
              "1  420689e2da77a9254362  ...     0\n",
              "2  b4d8ce47a727326a8916  ...     0\n",
              "3  197be9aa5fbef88659ee  ...     0\n",
              "4  a05cc194d3952fce5856  ...     0\n",
              "5  e1ddc63412371760c4f8  ...     0\n",
              "6  4ceb54eb7d9d41e447b8  ...     0\n",
              "7  911a6777272ef36f45f4  ...     0\n",
              "8  3038fbfa8d74e8e57c9d  ...     0\n",
              "9  b2ae47cfd86ae994440a  ...     0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xc9KjO0TS0Q",
        "colab_type": "code",
        "outputId": "016e7c87-fac7-48ad-b2bc-feb39f683783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(df1['label'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29186533737899145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJH9KvYHTaxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=df1['text']\n",
        "labels=df1['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDy3v4sxTxQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,\n",
        "                 variety=\"BrE\",\n",
        "                 user_abbrevs={},\n",
        "                 n_jobs=1):\n",
        "        \"\"\"\n",
        "        Text preprocessing transformer includes steps:\n",
        "            1. Text normalization\n",
        "            2. Punctuation removal\n",
        "            3. Stop words removal\n",
        "            4. Lemmatization\n",
        "        \n",
        "        variety - format of date (AmE - american type, BrE - british format) \n",
        "        user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
        "        n_jobs - parallel jobs to run\n",
        "        \"\"\"\n",
        "        self.variety = variety\n",
        "        self.user_abbrevs = user_abbrevs\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, *_):\n",
        "        X_copy = X.copy()\n",
        "        return X_copy.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_part(self, part):\n",
        "        return part.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_text(self, text):\n",
        "        text=self._clean_text(text)\n",
        "        normalized_text = self._normalize(text)\n",
        "        doc = nlp(normalized_text)\n",
        "        removed_punct = self._remove_punct(doc)\n",
        "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
        "        return self._lemmatize(removed_stop_words)\n",
        "\n",
        "    def _normalize(self, text):\n",
        "        # some issues in normalise package\n",
        "        try:\n",
        "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
        "        except:\n",
        "            return text\n",
        "\n",
        "    def _remove_punct(self, doc):\n",
        "        return [t for t in doc if t.text not in string.punctuation]\n",
        "\n",
        "    def _remove_stop_words(self, doc):\n",
        "        return [t for t in doc if not t.is_stop]\n",
        "\n",
        "    def _lemmatize(self, doc):\n",
        "        return ' '.join([t.lemma_ for t in doc])\n",
        "    \n",
        "    \n",
        "    def _clean_text(self,text):\n",
        "      replace_1 = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
        "      replace_2 = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "      try:\n",
        "        text=re.sub(r\"http\\S+\", \"\", text)\n",
        "      except:\n",
        "        print(text)\n",
        "      text = replace_1.sub(\"\", text)\n",
        "      text = replace_2.sub(\" \", text)\n",
        "      text=re.sub('\\s+',' ',text)\n",
        "      return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XrM501iV7uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "text = TextPreprocessor(n_jobs=-1).transform(df1['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHh25T3YV_wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2=[]\n",
        "for i in text:\n",
        "      lst=i.split()\n",
        "      text2.append(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPqtuAegWASD",
        "colab_type": "code",
        "outputId": "ab22a4d3-e3c1-4c31-d2ae-8eb34d66be81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(text2) \n",
        "sequences = tokenizer.texts_to_sequences(text2)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.',len(word_index))\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = max([len(s.split()) for s in text])\n",
        "tweets_pad = pad_sequences(sequences, maxlen=maxlen)\n",
        "print(tweets_pad.shape) \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found %s unique tokens. 28110\n",
            "(13842, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqCXuZ_gWFU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3=pd.concat([pd.DataFrame(text),pd.DataFrame(tweets_pad)],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6eGPkBYWGvL",
        "colab_type": "code",
        "outputId": "6d67d973-932a-4c08-b71a-e179563b9837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('Loading word vectors')\n",
        "embeddings_index = {} # We create a dictionary of word -> embedding\n",
        "f = open('/content/drive/My Drive/minor2/twitter2/glove.6B.100d.txt','r') # Open file\n",
        "# In the dataset, each line represents a new word embedding\n",
        "# The line starts with the word and the embedding values follow\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    word = values[0] # The first value is the word, the rest are the values of the embedding\n",
        "    values = np.asarray(values[1:], dtype='float32') # Load embedding\n",
        "    embeddings_index[word] = values # Add embedding to our embedding dictionary\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "400001it [00:22, 17770.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 400001 word vectors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pFZl2HaWIzm",
        "colab_type": "code",
        "outputId": "e8a84dfd-ade3-4094-c932-2ac9dbd97c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean = all_embs.mean() # Calculate mean\n",
        "emb_std = all_embs.std() # Calculate standard deviation\n",
        "emb_mean,emb_std"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0044520576, 0.40815717)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-WLaExOWKrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = len(word_index)+1\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAoyUdVAY9Ds",
        "colab_type": "code",
        "outputId": "69e2ff7b-ce0c-4f2e-eab7-fc0a39d5605a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28111, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FiOGtoTY9hO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history,name_of_fig):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    f=plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    f.savefig(name_of_fig, bbox_inches='tight', dpi=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8d3MO4aLEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "d5c096aa-1128-4126-9a48-09911b78c425"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            weights = [embedding_matrix],\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "#model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 58, 100)           2811100   \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 54, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,875,357\n",
            "Trainable params: 64,257\n",
            "Non-trainable params: 2,811,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNWZO-d8awQH",
        "colab_type": "code",
        "outputId": "08e0631e-8036-4665-f1d9-d67234ea9952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dropout(.3))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 58, 100)           2811100   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,891,601\n",
            "Trainable params: 80,501\n",
            "Non-trainable params: 2,811,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "861SxMVoayvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "caa7b2e3-b3bd-4449-d31b-91365671e1ff"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(GRU(units=100,dropout=0.2 , recurrent_dropout=0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 58, 100)           2811100   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100)               60300     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,871,501\n",
            "Trainable params: 60,401\n",
            "Non-trainable params: 2,811,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phE-GVv2a0-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "c12f2db6-7de8-47c8-87eb-4628923978d7"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dense(10, activation='sigmoid'))\n",
        "#model.add(GRU(units=100,dropout=0.2 , recurrent_dropout=0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 58, 100)           2811100   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5800)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                58010     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 2,869,121\n",
            "Trainable params: 58,021\n",
            "Non-trainable params: 2,811,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So6Z6Q4Oa3CS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "294e53e3-0bfb-464f-f1b1-36a5727fefbc"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            100,\n",
        "                            embeddings_initializer = Constant(embedding_matrix),\n",
        "                            input_length = maxlen,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "#model.add(Flatten())\n",
        "model.add(SimpleRNN(32, dropout=.2, recurrent_dropout=.2))\n",
        "model.add(layers.Dense(10, activation='sigmoid'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 58, 100)           2811100   \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 32)                4256      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 2,815,697\n",
            "Trainable params: 4,597\n",
            "Non-trainable params: 2,811,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwBDU8F9a5E-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_testing ,y_train, y_testing = train_test_split(df3, labels, test_size = 0.60, random_state = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEC0eHM6a7Ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test, X_val ,y_test, y_val = train_test_split(X_testing, y_testing, test_size = 0.50, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5bN9_una9S0",
        "colab_type": "code",
        "outputId": "eabd323e-ad58-46fc-8da3-ebb7a27ffefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "print('Training.....')\n",
        "history=model.fit(X_train.iloc[:,1:], y_train, batch_size=256,epochs=10,validation_data=(X_val.iloc[:,1:],y_val),verbose=True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "Train on 5536 samples, validate on 4153 samples\n",
            "Epoch 1/10\n",
            "5536/5536 [==============================] - 1s 218us/step - loss: 1.0847 - accuracy: 0.2896 - val_loss: 0.8869 - val_accuracy: 0.2933\n",
            "Epoch 2/10\n",
            "5536/5536 [==============================] - 1s 165us/step - loss: 0.8030 - accuracy: 0.3255 - val_loss: 0.6815 - val_accuracy: 0.6210\n",
            "Epoch 3/10\n",
            "5536/5536 [==============================] - 1s 168us/step - loss: 0.6595 - accuracy: 0.6656 - val_loss: 0.6282 - val_accuracy: 0.7058\n",
            "Epoch 4/10\n",
            "5536/5536 [==============================] - 1s 161us/step - loss: 0.6227 - accuracy: 0.7083 - val_loss: 0.6147 - val_accuracy: 0.7067\n",
            "Epoch 5/10\n",
            "5536/5536 [==============================] - 1s 163us/step - loss: 0.6126 - accuracy: 0.7094 - val_loss: 0.6099 - val_accuracy: 0.7067\n",
            "Epoch 6/10\n",
            "5536/5536 [==============================] - 1s 164us/step - loss: 0.6077 - accuracy: 0.7106 - val_loss: 0.6076 - val_accuracy: 0.7067\n",
            "Epoch 7/10\n",
            "5536/5536 [==============================] - 1s 162us/step - loss: 0.6050 - accuracy: 0.7103 - val_loss: 0.6065 - val_accuracy: 0.7067\n",
            "Epoch 8/10\n",
            "5536/5536 [==============================] - 1s 162us/step - loss: 0.6044 - accuracy: 0.7101 - val_loss: 0.6059 - val_accuracy: 0.7067\n",
            "Epoch 9/10\n",
            "5536/5536 [==============================] - 1s 166us/step - loss: 0.6029 - accuracy: 0.7099 - val_loss: 0.6055 - val_accuracy: 0.7067\n",
            "Epoch 10/10\n",
            "5536/5536 [==============================] - 1s 164us/step - loss: 0.6022 - accuracy: 0.7104 - val_loss: 0.6053 - val_accuracy: 0.7067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd9VE2EIbAf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_classes=model.predict_classes(X_test.iloc[:,1:])\n",
        "y_test = y_test.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMhDepKSbCnO",
        "colab_type": "code",
        "outputId": "639d84cf-5057-4865-e80c-fa29d2c15dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(len(X_val))\n",
        "print(len(y_val))\n",
        "print(df3.shape)\n",
        "print(len(labels))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4153\n",
            "4153\n",
            "(13842, 59)\n",
            "13842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RthvxFKWbFNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.DataFrame({'y_test': y_test, 'y_classes': y_classes[:,0]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpJywpSYbHSa",
        "colab_type": "code",
        "outputId": "133e3560-51d4-435b-ea1e-6c7b32287e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "1-np.mean(dataset['y_test'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7064772453647965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hssMNMbJA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDeLyd8ebLAg",
        "colab_type": "code",
        "outputId": "0db7b2a5-4cb2-460d-abf3-3230ef47c6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, y_classes)\n",
        "print('Accuracy:{}\\n'.format(accuracy))\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_classes)\n",
        "print('Precision:{}\\n'.format(precision))\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, y_classes)\n",
        "print('Recall:{}\\n'.format(recall))\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_classes)\n",
        "print('F1 score:{}\\n'.format(f1))\n",
        "matrix = confusion_matrix(y_test, y_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.7064772453647965\n",
            "\n",
            "Precision:0.0\n",
            "\n",
            "Recall:0.0\n",
            "\n",
            "F1 score:0.0\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2934    0]\n",
            " [1219    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q75wb_1tbbxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}