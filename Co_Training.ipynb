{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Co Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UjLUIozFNo99",
        "twRDck_4Nu7_",
        "krTAfaj8NJ2J",
        "qWMl6ujeNQP8",
        "SYi4pRdYPJ-F",
        "9nGNDI5hNYBz"
      ],
      "mount_file_id": "1HKNpo5eSHoNZpz4XY99v38qFX0UyF-qy",
      "authorship_tag": "ABX9TyO4DGOVrqW5zKE1HeGbk7el",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tushitgarg/Hate-Speech-Content-Moderation/blob/master/Co_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjLUIozFNo99",
        "colab_type": "text"
      },
      "source": [
        "# Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEXHHI2D-qwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "2d3c1cc8-0f45-4a90-b3b9-c2ad525d12c8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pprint as pp\n",
        "! pip install normalise\n",
        "import nltk\n",
        "nltk.download('names')\n",
        "nltk.download('brown')\n",
        "\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "import string\n",
        "import spacy \n",
        "import en_core_web_sm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from normalise import normalise\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,GRU, SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import layers\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting normalise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/2d/f06cf3d3714502dec10e19238a5da201b71ce198165beda9c1adaf5063da/normalise-0.1.8-py3-none-any.whl (15.7MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from normalise) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from normalise) (1.18.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from normalise) (3.2.5)\n",
            "Collecting roman\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/f2/29d1d069555855ed49c74b627e6af73cec7a5f4de27c200ea0d760939da4/roman-3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from normalise) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->normalise) (0.15.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->normalise) (1.12.0)\n",
            "Installing collected packages: roman, normalise\n",
            "Successfully installed normalise-0.1.8 roman-3.2\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.semi_supervised.label_propagation module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.semi_supervised. Anything that cannot be imported from sklearn.semi_supervised is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelPropagation from version 0.18 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twRDck_4Nu7_",
        "colab_type": "text"
      },
      "source": [
        "# Text Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILunTKA5JcZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,\n",
        "                 variety=\"BrE\",\n",
        "                 user_abbrevs={},\n",
        "                 n_jobs=1):\n",
        "        \"\"\"\n",
        "        Text preprocessing transformer includes steps:\n",
        "            1. Text normalization\n",
        "            2. Punctuation removal\n",
        "            3. Stop words removal\n",
        "            4. Lemmatization\n",
        "        \n",
        "        variety - format of date (AmE - american type, BrE - british format) \n",
        "        user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
        "        n_jobs - parallel jobs to run\n",
        "        \"\"\"\n",
        "        self.variety = variety\n",
        "        self.user_abbrevs = user_abbrevs\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, *_):\n",
        "        X_copy = X.copy()\n",
        "        return X_copy.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_part(self, part):\n",
        "        return part.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_text(self, text):\n",
        "        text=self._clean_text(text)\n",
        "        normalized_text = self._normalize(text)\n",
        "        doc = nlp(normalized_text)\n",
        "        removed_punct = self._remove_punct(doc)\n",
        "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
        "        return self._lemmatize(removed_stop_words)\n",
        "\n",
        "    def _normalize(self, text):\n",
        "        # some issues in normalise package\n",
        "        try:\n",
        "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
        "        except:\n",
        "            return text\n",
        "\n",
        "    def _remove_punct(self, doc):\n",
        "        return [t for t in doc if t.text not in string.punctuation]\n",
        "\n",
        "    def _remove_stop_words(self, doc):\n",
        "        return [t for t in doc if not t.is_stop]\n",
        "\n",
        "    def _lemmatize(self, doc):\n",
        "        return ' '.join([t.lemma_ for t in doc])\n",
        "    \n",
        "    \n",
        "    def _clean_text(self,text):\n",
        "      replace_1 = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
        "      replace_2 = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "      try:\n",
        "        text=re.sub(r\"http\\S+\", \"\", text)\n",
        "      except:\n",
        "        print(text)\n",
        "      text = replace_1.sub(\"\", text)\n",
        "      text = replace_2.sub(\" \", text)\n",
        "      text=re.sub('\\s+',' ',text)\n",
        "      return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZTA2ev__aWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f034dbca-84d3-4e8d-c574-627e9d60df43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCYubLAJ_m-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62b51f80-de34-4935-cf5a-6ba6e11e5ec7"
      },
      "source": [
        "cd '/content/drive/My Drive/minor2/Hate-Speech-Content-Moderation/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/minor2/Hate-Speech-Content-Moderation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK_v7dObM3G-",
        "colab_type": "text"
      },
      "source": [
        "# Loading datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFr62OV9_pRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3bcbcf62-a560-4549-8ed6-6cb74aa7bda2"
      },
      "source": [
        "quora=pd.read_excel('quora.xlsx')\n",
        "quora.head(5)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8eeb2fa6a60d93c5ce3c</td>\n",
              "      <td>What is the difference between real, true, act...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>420689e2da77a9254362</td>\n",
              "      <td>Can an applicant with JEST score in PhD merit ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b4d8ce47a727326a8916</td>\n",
              "      <td>How can I get the syllabus of JEE Advanced for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>197be9aa5fbef88659ee</td>\n",
              "      <td>What is fee structure of KLE Sheshagiri Colleg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a05cc194d3952fce5856</td>\n",
              "      <td>How do I pick few wines that will go with food...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... label\n",
              "0  8eeb2fa6a60d93c5ce3c  ...     0\n",
              "1  420689e2da77a9254362  ...     0\n",
              "2  b4d8ce47a727326a8916  ...     0\n",
              "3  197be9aa5fbef88659ee  ...     0\n",
              "4  a05cc194d3952fce5856  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWi7_qAKD0rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b005b82b-f875-4198-a232-569c48f309ce"
      },
      "source": [
        "twitter = pd.read_excel('twitter2_data.xlsx')\n",
        "twitter.drop(['level_0','index','Unnamed: 0'],axis=1,inplace=True)\n",
        "twitter.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5e4ce1ac5ca387d4c86d31d9</td>\n",
              "      <td>RT @fairbairn77: I'm not sexist or anything bu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5e4cebeb5ca387d4c86d4ec1</td>\n",
              "      <td>RT @colonelkickhead: Apparently walking a catw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5e4d048f5ca387d4c86d8084</td>\n",
              "      <td>RT @athenahollow: @freebsdgirl He REALLY picke...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5e4ce2125ca387d4c86d32a6</td>\n",
              "      <td>@JohnJohnisKilla Call me sexist or whatever it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5e4ceb135ca387d4c86d4cd1</td>\n",
              "      <td>I don't understand mean girls. And certainly n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id  ... label\n",
              "0  5e4ce1ac5ca387d4c86d31d9  ...     1\n",
              "1  5e4cebeb5ca387d4c86d4ec1  ...     0\n",
              "2  5e4d048f5ca387d4c86d8084  ...     0\n",
              "3  5e4ce2125ca387d4c86d32a6  ...     1\n",
              "4  5e4ceb135ca387d4c86d4cd1  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHd9jT7RD80B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "85539558-2f0a-4327-8d3f-957270e65dae"
      },
      "source": [
        "wiki=pd.read_excel('wiki.xlsx')\n",
        "wiki.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4873f24af8928f39</td>\n",
              "      <td>Oh BedWetter... please stop your furious back-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aa343515b55c73b8</td>\n",
              "      <td>There's no conflict, a court martial can end w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c7888738107f928a</td>\n",
              "      <td>what????how are the ones from willking1979's t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48a42a867206a816</td>\n",
              "      <td>\"\\n\\nabuse or consentual??\\n\\n\"\"Homolka would ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2c103909d79f9876</td>\n",
              "      <td>\"==Talk:\"\"Lane Splitting\"\"==\\n\\nDennis, why do...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                               text  label\n",
              "0  4873f24af8928f39  Oh BedWetter... please stop your furious back-...      1\n",
              "1  aa343515b55c73b8  There's no conflict, a court martial can end w...      0\n",
              "2  c7888738107f928a  what????how are the ones from willking1979's t...      0\n",
              "3  48a42a867206a816  \"\\n\\nabuse or consentual??\\n\\n\"\"Homolka would ...      0\n",
              "4  2c103909d79f9876  \"==Talk:\"\"Lane Splitting\"\"==\\n\\nDennis, why do...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSCWehO3H2x0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f12b51dd-9f1c-463d-f75b-2550f7214c2c"
      },
      "source": [
        "wiki.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10204, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUvSkcXpIKyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "51f8dfef-6076-412c-acf5-a3be0b63ad78"
      },
      "source": [
        "twitter.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10841, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQjOiUwGIXyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b55c6119-4106-4368-e958-4ba5a7fcfd22"
      },
      "source": [
        "quora.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13842, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QIrTVZbMqBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(twitter['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRIGCX59MqGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(quora['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJTtdhylMqOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(quora['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EomhQ_QnM_EE",
        "colab_type": "text"
      },
      "source": [
        "# Extracting text and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbStT9jZK9kV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_text=twitter['text']\n",
        "twitter_labels=twitter['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLHRCUPuK9pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_text=quora['text']\n",
        "quora_labels = quora['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dkkch82K9vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_text=wiki['text']\n",
        "wiki_labels=wiki['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krTAfaj8NJ2J",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning and preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsGzALH-JNye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "51cf591c-c3f3-48ea-8d31-e77e60dcbeb9"
      },
      "source": [
        "%%time\n",
        "twitter_text = TextPreprocessor(n_jobs=-1).transform(twitter['text'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 53s, sys: 885 ms, total: 1min 54s\n",
            "Wall time: 1min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTSzZcTsJnwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "quora_text = TextPreprocessor(n_jobs=-1).transform(quora['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "farirVQ2JuZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a5be65dd-891f-4755-9280-a47d071c5459"
      },
      "source": [
        "%%time\n",
        "wiki_text = TextPreprocessor(n_jobs=-1).transform(wiki['text'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 58s, sys: 1.23 s, total: 2min 59s\n",
            "Wall time: 2min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWMl6ujeNQP8",
        "colab_type": "text"
      },
      "source": [
        "# Splitting the text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSY5-8CVJxf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_text2=[]\n",
        "for i in twitter_text:\n",
        "      lst=i.split()\n",
        "      twitter_text2.append(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KrsdVX2KFqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_text2=[]\n",
        "for i in quora_text:\n",
        "      lst=i.split()\n",
        "      quora_text2.append(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRZRH1nHKF-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_text2=[]\n",
        "for i in wiki_text:\n",
        "      lst=i.split()\n",
        "      wiki_text2.append(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYi4pRdYPJ-F",
        "colab_type": "text"
      },
      "source": [
        "# Loading Glove embeddings and making embeddings dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "556h74KKPEQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "161dc2fc-51ad-43b2-dd33-3fe09f7610e9"
      },
      "source": [
        "print('Loading word vectors')\n",
        "embeddings_index = {} # We create a dictionary of word -> embedding\n",
        "f = open('/content/drive/My Drive/minor2/twitter2/glove.6B.100d.txt','r') # Open file\n",
        "# In the dataset, each line represents a new word embedding\n",
        "# The line starts with the word and the embedding values follow\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    word = values[0] # The first value is the word, the rest are the values of the embedding\n",
        "    values = np.asarray(values[1:], dtype='float32') # Load embedding\n",
        "    embeddings_index[word] = values # Add embedding to our embedding dictionary\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "400001it [00:16, 24905.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 400001 word vectors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izzhlIQdPolJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "ed6e6306-54af-4e2e-f7b5-21fc21083adb"
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean = all_embs.mean() # Calculate mean\n",
        "emb_std = all_embs.std() # Calculate standard deviation\n",
        "emb_mean,emb_std"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0044520576, 0.40815717)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nGNDI5hNYBz",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizing and padding the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt5eieQxKQlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a480c720-dc52-4541-acdf-54ebafe3d86f"
      },
      "source": [
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(twitter_text2) \n",
        "sequences = tokenizer.texts_to_sequences(twitter_text2)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.',len(word_index))\n",
        "twitter_maxlen = max([len(s.split()) for s in twitter_text])\n",
        "tweets_pad = pad_sequences(sequences, maxlen=twitter_maxlen)\n",
        "print(tweets_pad.shape) \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found %s unique tokens. 14884\n",
            "(10841, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an1jxo2mLbdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0a9dbb9a-f8a9-4178-ae76-fbecc971ea42"
      },
      "source": [
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(quora_text2) \n",
        "sequences = tokenizer.texts_to_sequences(quora_text2)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.',len(word_index))\n",
        "quora_maxlen = max([len(s.split()) for s in quora_text])\n",
        "quora_pad = pad_sequences(sequences, maxlen=quora_maxlen)\n",
        "print(quora_pad.shape) \n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found %s unique tokens. 28110\n",
            "(13842, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xt_6VNFUo77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(wiki_text2) \n",
        "sequences = tokenizer.texts_to_sequences(wiki_text2)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.',len(word_index))\n",
        "wiki_maxlen = max([len(s.split()) for s in wiki_text])\n",
        "wiki_pad = pad_sequences(sequences, maxlen=wiki_maxlen)\n",
        "print(wiki_pad.shape) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpkjVWOtN8vB",
        "colab_type": "text"
      },
      "source": [
        "# Making dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5D0WqO5MStA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_df=pd.concat([pd.DataFrame(twitter_text),pd.DataFrame(tweets_pad)],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULvzSMJGOJ_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_df=pd.concat([pd.DataFrame(quora_text),pd.DataFrame(quora_pad)],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKlupcqtORky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_df=pd.concat([pd.DataFrame(wiki_text),pd.DataFrame(wiki_pad)],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua6_98zDPhpB",
        "colab_type": "text"
      },
      "source": [
        "# Embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEniVgMaPii7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "f6218f71-d8a8-4b9c-ea17-d1a282ec86d7"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-25359f9a8432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'dict_values' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m1L_mLjdGsj",
        "colab_type": "text"
      },
      "source": [
        "# Co training Iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWqSFVA2fNB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora=pd.read_excel('quora.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiDxOFyBfMxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter = pd.read_excel('twitter2_data.xlsx')\n",
        "twitter.drop(['level_0','index','Unnamed: 0'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCOtKwh2fMZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki=pd.read_excel('wiki.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lk2BBOqfnsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora.columns = twitter.columns\n",
        "wiki.columns = twitter.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ETnvkDeiYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LoadGlove():\n",
        "  print('Loading word vectors')\n",
        "  embeddings_index = {}\n",
        "  f = open('/content/drive/My Drive/minor2/twitter2/glove.6B.100d.txt','r')\n",
        "  for line in tqdm(f):\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      values = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = values\n",
        "  f.close()\n",
        "  print('Found %s word vectors.' % len(embeddings_index))\n",
        "  return embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRgjHZ5AeNuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_embedding_matrix(tokenizer,emb_mean,emb_std,embeddings_index):\n",
        "  embedding_dim = 100\n",
        "  word_index = tokenizer.word_index\n",
        "  num_words = len(word_index)+1\n",
        "  embedding_matrix = np.random.normal(emb_mean, emb_std, (num_words, embedding_dim))\n",
        "  for word, i in word_index.items():\n",
        "      embedding_vector = embeddings_index.get(word)\n",
        "      if embedding_vector is not None: \n",
        "          embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQcPVWVCdZe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CoTrain(Train,Test):\n",
        "  embeddings_index = LoadGlove()\n",
        "  train_text = Train['text']\n",
        "  train_labels = Train['label']\n",
        "  test_text = Test['text']\n",
        "  test_labels = Test['label']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ulOD5kzW4Wc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "f4cbd46a-fb70-4225-cc39-5b963ef090e5"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "x = twitter\n",
        "yl = quora.sample(frac=0.2)\n",
        "yu = quora.drop(list(yl.index))\n",
        "K = 5\n",
        "r = len(yl)//5\n",
        "for k in range(K+1):\n",
        "  #print(x.shape)\n",
        "  #CoTrain(x,yu)\n",
        "  z = yl.iloc[:r,:]\n",
        "  yl = yl.drop(list(z.index))\n",
        "  x =  pd.concat([x,z],axis=0)\n",
        "  shuffle(x)\n",
        "  x.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10841, 3)\n",
            "(2215, 3)\n",
            "(11394, 3)\n",
            "(1662, 3)\n",
            "(11947, 3)\n",
            "(1109, 3)\n",
            "(12500, 3)\n",
            "(556, 3)\n",
            "(13053, 3)\n",
            "(3, 3)\n",
            "(13606, 3)\n",
            "(0, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnkbigXoe51l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}